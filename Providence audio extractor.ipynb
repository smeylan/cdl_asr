{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d527345-9bca-4817-bb2c-55c9b042e984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Installing package into ‘/home/stephan/R/x86_64-pc-linux-gnu-library/4.2’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinstalling childesr version 0.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/childesr_0.2.3.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 22865 bytes (22 KB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 22 KB\n",
      "\n",
      "\n",
      "* installing *source* package ‘childesr’ ...\n",
      "** package ‘childesr’ successfully unpacked and MD5 sums checked\n",
      "** using staged installation\n",
      "** R\n",
      "** inst\n",
      "** byte-compile and prepare package for lazy loading\n",
      "** help\n",
      "*** installing help indices\n",
      "** building package indices\n",
      "** installing vignettes\n",
      "** testing if installed package can be loaded from temporary location\n",
      "** testing if installed package can be loaded from final location\n",
      "** testing if installed package keeps a record of temporary installation path\n",
      "* DONE (childesr)\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: The downloaded source packages are in\n",
      "\t‘/tmp/RtmpehPKQ3/downloaded_packages’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import childespy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bdf593f-7598-44ae-9749-6bc36e1f60e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using current database version: '2021.1'.\n",
      "\n",
      "R[write to console]: Getting data from 7 children in 1 corpus ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the table of Providence Utterances\n",
    "prov_utts = childespy.get_utterances(corpus = \"Providence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f12c7618-0a39-4963-96d4-9de25a852fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using current database version: '2021.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prov_transcripts = childespy.get_transcripts(corpus = \"Providence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c8cf86-13da-421a-96bd-3abf65c660a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_transcripts['filename_identifier'] = [os.path.basename(x).replace('.xml','') for x in prov_transcripts['filename']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "428a9760-3915-4209-a173-5440f2b0c30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_utts_with_filenames = prov_utts.merge(prov_transcripts[['transcript_id','filename_identifier']], on=['transcript_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "627a1a70-cacc-4094-ab7f-46650f042c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_utts_with_filenames['media_duration'] = prov_utts_with_filenames['media_end'] - prov_utts_with_filenames['media_start'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a8943f-0808-4a41-9092-957af2efe1c6",
   "metadata": {},
   "source": [
    "# Sample Utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c5a6158-3eef-4929-b355-23ac66aa2202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_utterances(prov_utts_with_filenames, num_transcripts, num_utts_per_transcript):\n",
    "\n",
    "    print(prov_utts_with_filenames.shape)\n",
    "    prov_utts_with_filenames['num_words'] = [len(x.split(' ')) for x in prov_utts_with_filenames['gloss']]\n",
    "    prov_utts_with_filenames['contains_xxx'] = prov_utts_with_filenames['gloss'].str.contains('xxx')\n",
    "    prov_utts_with_filenames['contains_yyy'] = prov_utts_with_filenames['gloss'].str.contains('yyy')\n",
    "    \n",
    "    usable_utts = prov_utts_with_filenames.loc[\n",
    "             ~prov_utts_with_filenames.contains_xxx & ~prov_utts_with_filenames.contains_yyy\n",
    "    ]\n",
    "    allowable_speakers = ('CHI','MOT')\n",
    "    usable_utts = usable_utts.loc[usable_utts.num_words >= 2]\n",
    "    usable_utts = usable_utts.loc[usable_utts.speaker_code.isin(allowable_speakers)]\n",
    "    usable_utts = usable_utts.loc[~np.isnan(usable_utts.media_duration)]\n",
    "    print(usable_utts.shape)\n",
    "    \n",
    "    chi_utts = usable_utts.loc[usable_utts.speaker_code == 'CHI']\n",
    "    mot_utts = usable_utts.loc[usable_utts.speaker_code == 'MOT']\n",
    "    \n",
    "    chi_utts_by_transcript = [v for k, v in chi_utts.groupby(['filename_identifier'])]\n",
    "    mot_utts_by_transcript = [v for k, v in mot_utts.groupby(['filename_identifier'])]\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    # Choose transcripts\n",
    "    chi_transcript_choices = np.random.choice(range(len(chi_utts_by_transcript)), size=num_transcripts, replace=False)\n",
    "    mot_transcript_choices = np.random.choice(range(len(mot_utts_by_transcript)), size=num_transcripts, replace=False)\n",
    "    \n",
    "    # Within each transcript, choose utterances\n",
    "    sampled_utts = []\n",
    "    for chi_transcript_choice in chi_transcript_choices:\n",
    "        possible_utts = chi_utts_by_transcript[chi_transcript_choice]\n",
    "        sampled_utt = np.random.choice(range(len(possible_utts)), size=num_utts_per_transcript, replace=False)[0]\n",
    "        sampled_utts.append(possible_utts.iloc[sampled_utt].id)\n",
    "        \n",
    "    for mot_transcript_choice in mot_transcript_choices:\n",
    "        possible_utts = mot_utts_by_transcript[mot_transcript_choice]\n",
    "        sampled_utt = np.random.choice(range(len(possible_utts)), size=num_utts_per_transcript, replace=False)[0]        \n",
    "        sampled_utts.append(possible_utts.iloc[sampled_utt].id)\n",
    "    \n",
    "    return(sampled_utts)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1db907-5626-49ee-a7bd-f9fa3abf0f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460061, 29)\n",
      "(195144, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2743583/400814402.py:20: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  chi_utts_by_transcript = [v for k, v in chi_utts.groupby(['filename_identifier'])]\n",
      "/tmp/ipykernel_2743583/400814402.py:21: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  mot_utts_by_transcript = [v for k, v in mot_utts.groupby(['filename_identifier'])]\n"
     ]
    }
   ],
   "source": [
    "utt_indices_to_score = sample_utterances(prov_utts_with_filenames, 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "178d7517-dad6-4ffb-b566-5eaea96f4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "utts_to_score = prov_utts_with_filenames.loc[prov_utts_with_filenames.id.isin(utt_indices_to_score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc6ea8e9-637f-478e-9ba6-5ad31c9852a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>stem</th>\n",
       "      <th>actual_phonology</th>\n",
       "      <th>model_phonology</th>\n",
       "      <th>type</th>\n",
       "      <th>language</th>\n",
       "      <th>num_morphemes</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>...</th>\n",
       "      <th>collection_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>target_child_id</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>filename_identifier</th>\n",
       "      <th>media_duration</th>\n",
       "      <th>num_words</th>\n",
       "      <th>contains_xxx</th>\n",
       "      <th>contains_yyy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18000</th>\n",
       "      <td>17278081</td>\n",
       "      <td>ding dong</td>\n",
       "      <td>ding dong</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>416</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>336</td>\n",
       "      <td>23473</td>\n",
       "      <td>23471</td>\n",
       "      <td>43232</td>\n",
       "      <td>020411</td>\n",
       "      <td>1.998</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44751</th>\n",
       "      <td>17323545</td>\n",
       "      <td>would you like to hear promised land</td>\n",
       "      <td>will you like to hear promise land</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>question</td>\n",
       "      <td>eng</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1653</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>336</td>\n",
       "      <td>23473</td>\n",
       "      <td>23471</td>\n",
       "      <td>43247</td>\n",
       "      <td>021108</td>\n",
       "      <td>6.259</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77965</th>\n",
       "      <td>17342025</td>\n",
       "      <td>I too</td>\n",
       "      <td>I too</td>\n",
       "      <td>ʌ tu</td>\n",
       "      <td>aɪ tuː</td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1186</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>336</td>\n",
       "      <td>23487</td>\n",
       "      <td>23487</td>\n",
       "      <td>43268</td>\n",
       "      <td>010218</td>\n",
       "      <td>0.963</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92097</th>\n",
       "      <td>17359147</td>\n",
       "      <td>tangled up moo</td>\n",
       "      <td>tangle up moo</td>\n",
       "      <td>ɛŋə ʌp mu</td>\n",
       "      <td>tæŋɡəld ʌp muː</td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>789</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>336</td>\n",
       "      <td>23487</td>\n",
       "      <td>23487</td>\n",
       "      <td>43275</td>\n",
       "      <td>010620</td>\n",
       "      <td>4.654</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96534</th>\n",
       "      <td>17358854</td>\n",
       "      <td>over the bumps</td>\n",
       "      <td>over the bump</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>454</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>336</td>\n",
       "      <td>23488</td>\n",
       "      <td>23487</td>\n",
       "      <td>43288</td>\n",
       "      <td>020007</td>\n",
       "      <td>1.790</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                 gloss  \\\n",
       "18000  17278081                             ding dong   \n",
       "44751  17323545  would you like to hear promised land   \n",
       "77965  17342025                                 I too   \n",
       "92097  17359147                        tangled up moo   \n",
       "96534  17358854                        over the bumps   \n",
       "\n",
       "                                     stem actual_phonology model_phonology  \\\n",
       "18000                           ding dong                                    \n",
       "44751  will you like to hear promise land                                    \n",
       "77965                               I too             ʌ tu          aɪ tuː   \n",
       "92097                       tangle up moo        ɛŋə ʌp mu  tæŋɡəld ʌp muː   \n",
       "96534                       over the bump                                    \n",
       "\n",
       "              type language  num_morphemes  num_tokens  utterance_order  ...  \\\n",
       "18000  declarative      eng              2           2              416  ...   \n",
       "44751     question      eng              9           7             1653  ...   \n",
       "77965  declarative      eng              2           2             1186  ...   \n",
       "92097  declarative      eng              4           3              789  ...   \n",
       "96534  declarative      eng              4           3              454  ...   \n",
       "\n",
       "      collection_id corpus_id speaker_id target_child_id transcript_id  \\\n",
       "18000            21       336      23473           23471         43232   \n",
       "44751            21       336      23473           23471         43247   \n",
       "77965            21       336      23487           23487         43268   \n",
       "92097            21       336      23487           23487         43275   \n",
       "96534            21       336      23488           23487         43288   \n",
       "\n",
       "      filename_identifier  media_duration num_words  contains_xxx  \\\n",
       "18000              020411           1.998         2         False   \n",
       "44751              021108           6.259         7         False   \n",
       "77965              010218           0.963         2         False   \n",
       "92097              010620           4.654         3         False   \n",
       "96534              020007           1.790         3         False   \n",
       "\n",
       "       contains_yyy  \n",
       "18000         False  \n",
       "44751         False  \n",
       "77965         False  \n",
       "92097         False  \n",
       "96534         False  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utts_to_score.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b993f167-d0c8-41f0-9307-48714e1cb01f",
   "metadata": {},
   "source": [
    "# Extract WAVs from MP4s For Sampled Utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47724092-5753-43fe-b506-30a8d01580ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wav_from_mp4(base_media_path, utterance_record, base_output_folder):        \n",
    "    mp4_filename = os.path.join(\n",
    "        base_media_path,\n",
    "        utterance_record['target_child_name'],\n",
    "        utterance_record['filename_identifier']+'.mp4')\n",
    "        \n",
    "    output_folder = base_output_folder    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)        \n",
    "    output_file = os.path.join(output_folder, str(utterance_record['id'])+'.wav')    \n",
    "    command = \"ffmpeg -hide_banner -loglevel error -i \"+mp4_filename+\" -ss \"+str(utterance_record['media_start'])+  \" -t \"+str(utterance_record['media_duration'])+\" -y -ac 1 -q:a 0 -map a -b:a 16k \"+output_file\n",
    "    print(command)\n",
    "    os.system(command)\n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        return(output_file)\n",
    "    else: \n",
    "        return('Error extracting WAV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6287861b-7ff0-4bd6-a9f1-274c6e249914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hd1/Providence_videos/media.talkbank.org/phon/Eng-NA/Providence/Ethan/010218.mp4: No such file or directory\n",
      "/hd1/Providence_videos/media.talkbank.org/phon/Eng-NA/Providence/Ethan/010620.mp4: No such file or directory\n",
      "/hd1/Providence_videos/media.talkbank.org/phon/Eng-NA/Providence/Ethan/020007.mp4: No such file or directory\n",
      "/hd1/Providence_videos/media.talkbank.org/phon/Eng-NA/Providence/Ethan/020709.mp4: No such file or directory\n",
      "/hd1/Providence_videos/media.talkbank.org/phon/Eng-NA/Providence/Ethan/021101.mp4: No such file or directory\n",
      "/hd1/Providence_videos/media.talkbank.org/phon/Eng-NA/Providence/Ethan/021018.mp4: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "base_media_path = '/hd1/Providence_videos/media.talkbank.org/phon/Eng-NA/Providence/'\n",
    "utterance_records = utts_to_score.to_dict('records')\n",
    "base_output_folder = 'extracted_wavs'\n",
    "\n",
    "utts_to_score['output_wav'] = [extract_wav_from_mp4(base_media_path, x, base_output_folder) for x in utterance_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c85f1d3d-9f21-4558-9296-fbbdd8983ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>stem</th>\n",
       "      <th>actual_phonology</th>\n",
       "      <th>model_phonology</th>\n",
       "      <th>type</th>\n",
       "      <th>language</th>\n",
       "      <th>num_morphemes</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>...</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>target_child_id</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>filename_identifier</th>\n",
       "      <th>media_duration</th>\n",
       "      <th>num_words</th>\n",
       "      <th>contains_xxx</th>\n",
       "      <th>contains_yyy</th>\n",
       "      <th>output_wav</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18000</th>\n",
       "      <td>17278081</td>\n",
       "      <td>ding dong</td>\n",
       "      <td>ding dong</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>416</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23473</td>\n",
       "      <td>23471</td>\n",
       "      <td>43232</td>\n",
       "      <td>020411</td>\n",
       "      <td>1.998</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17278081.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44751</th>\n",
       "      <td>17323545</td>\n",
       "      <td>would you like to hear promised land</td>\n",
       "      <td>will you like to hear promise land</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>question</td>\n",
       "      <td>eng</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1653</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23473</td>\n",
       "      <td>23471</td>\n",
       "      <td>43247</td>\n",
       "      <td>021108</td>\n",
       "      <td>6.259</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17323545.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151803</th>\n",
       "      <td>17425579</td>\n",
       "      <td>boots boots</td>\n",
       "      <td>boot boot</td>\n",
       "      <td>bu bu</td>\n",
       "      <td>buːts buːts</td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1629</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23495</td>\n",
       "      <td>23495</td>\n",
       "      <td>43324</td>\n",
       "      <td>010719</td>\n",
       "      <td>3.345</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17425579.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160848</th>\n",
       "      <td>17441440</td>\n",
       "      <td>I don't think you've ever had eggplant but Mom...</td>\n",
       "      <td>I do think you ever have but Mommy love</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>1746</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23497</td>\n",
       "      <td>23495</td>\n",
       "      <td>43335</td>\n",
       "      <td>020011</td>\n",
       "      <td>3.487</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17441440.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179481</th>\n",
       "      <td>17437309</td>\n",
       "      <td>come here angel</td>\n",
       "      <td>come here angel</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>315</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23497</td>\n",
       "      <td>23495</td>\n",
       "      <td>43344</td>\n",
       "      <td>020227</td>\n",
       "      <td>0.777</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17437309.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197711</th>\n",
       "      <td>17457797</td>\n",
       "      <td>was it</td>\n",
       "      <td>be it</td>\n",
       "      <td>wʌz ɪt</td>\n",
       "      <td>wɑz ɪt</td>\n",
       "      <td>question</td>\n",
       "      <td>eng</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23495</td>\n",
       "      <td>23495</td>\n",
       "      <td>43364</td>\n",
       "      <td>020813</td>\n",
       "      <td>1.198</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17457797.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200312</th>\n",
       "      <td>17458412</td>\n",
       "      <td>we did it</td>\n",
       "      <td>we do it</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>imperative_emphatic</td>\n",
       "      <td>eng</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>207</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23497</td>\n",
       "      <td>23495</td>\n",
       "      <td>43361</td>\n",
       "      <td>020721</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17458412.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206192</th>\n",
       "      <td>17479586</td>\n",
       "      <td>red red</td>\n",
       "      <td>red red</td>\n",
       "      <td>rɛː rɛːd</td>\n",
       "      <td>ɹɛd ɹɛd</td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1408</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23495</td>\n",
       "      <td>23495</td>\n",
       "      <td>43366</td>\n",
       "      <td>020904</td>\n",
       "      <td>9.045</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17479586.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206957</th>\n",
       "      <td>17466565</td>\n",
       "      <td>um the pink one</td>\n",
       "      <td>the pink one</td>\n",
       "      <td>ʌm də pɪŋk wə</td>\n",
       "      <td>ʌm ðə pɪŋk wʌn</td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>192</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23495</td>\n",
       "      <td>23495</td>\n",
       "      <td>43367</td>\n",
       "      <td>020909</td>\n",
       "      <td>5.157</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17466565.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207669</th>\n",
       "      <td>17476426</td>\n",
       "      <td>there it is</td>\n",
       "      <td>there it be</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>904</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23497</td>\n",
       "      <td>23495</td>\n",
       "      <td>43367</td>\n",
       "      <td>020909</td>\n",
       "      <td>2.040</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17476426.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215409</th>\n",
       "      <td>17475018</td>\n",
       "      <td>and the goblins ran back to their homes</td>\n",
       "      <td>and the goblin run back to their home</td>\n",
       "      <td>n̩ ə ɡɑblɪŋz wæ̃n bæk tu ðeɪə homz</td>\n",
       "      <td>ænd ðə ɡɑblɪnz ɹæn bæk tuː ðɛɹ hoʊmz</td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>304</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23495</td>\n",
       "      <td>23495</td>\n",
       "      <td>43365</td>\n",
       "      <td>020819</td>\n",
       "      <td>4.216</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17475018.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217071</th>\n",
       "      <td>17480806</td>\n",
       "      <td>that is a lot of rings</td>\n",
       "      <td>that be a lot of ring</td>\n",
       "      <td>ðæd ɪz ə lɑd ə bɪŋz</td>\n",
       "      <td>ðæt ɪz ə lɑt ʌv ɹɪŋz</td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>576</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23495</td>\n",
       "      <td>23495</td>\n",
       "      <td>43369</td>\n",
       "      <td>020923</td>\n",
       "      <td>2.095</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17480806.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226738</th>\n",
       "      <td>17501401</td>\n",
       "      <td>is that you or me</td>\n",
       "      <td>be that you or me</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>question</td>\n",
       "      <td>eng</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1330</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23497</td>\n",
       "      <td>23495</td>\n",
       "      <td>43381</td>\n",
       "      <td>030323</td>\n",
       "      <td>0.993</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17501401.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237362</th>\n",
       "      <td>17492751</td>\n",
       "      <td>yeah would you like me to get you a bowl of so...</td>\n",
       "      <td>yeah will you like me to get you a bowl of som...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>question</td>\n",
       "      <td>eng</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23497</td>\n",
       "      <td>23495</td>\n",
       "      <td>43363</td>\n",
       "      <td>020806</td>\n",
       "      <td>3.340</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17492751.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252153</th>\n",
       "      <td>17513189</td>\n",
       "      <td>eggs eggs</td>\n",
       "      <td>egg egg</td>\n",
       "      <td>iɡz (.) ɛɡz</td>\n",
       "      <td>ɛɡz (.) ɛɡz</td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>298</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23510</td>\n",
       "      <td>23510</td>\n",
       "      <td>43401</td>\n",
       "      <td>010410</td>\n",
       "      <td>3.173</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17513189.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254880</th>\n",
       "      <td>17516827</td>\n",
       "      <td>read please</td>\n",
       "      <td>read please</td>\n",
       "      <td>riʔ plis</td>\n",
       "      <td>ɹiːd pliːz</td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>381</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23495</td>\n",
       "      <td>23495</td>\n",
       "      <td>43389</td>\n",
       "      <td>040002</td>\n",
       "      <td>1.256</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17516827.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258662</th>\n",
       "      <td>17518193</td>\n",
       "      <td>where's the parrot</td>\n",
       "      <td>where the parrot</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>question</td>\n",
       "      <td>eng</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23511</td>\n",
       "      <td>23510</td>\n",
       "      <td>43404</td>\n",
       "      <td>010502</td>\n",
       "      <td>2.669</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17518193.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260876</th>\n",
       "      <td>17534534</td>\n",
       "      <td>I'll eat it you wanna give it to me</td>\n",
       "      <td>I eat it you want give it to me</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>question</td>\n",
       "      <td>eng</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>1300</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23511</td>\n",
       "      <td>23510</td>\n",
       "      <td>43407</td>\n",
       "      <td>010604</td>\n",
       "      <td>2.090</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17534534.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266449</th>\n",
       "      <td>17533444</td>\n",
       "      <td>I see a kid on a mat</td>\n",
       "      <td>I see a kid on a mat</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>999</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23511</td>\n",
       "      <td>23510</td>\n",
       "      <td>43412</td>\n",
       "      <td>010710</td>\n",
       "      <td>5.680</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17533444.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277281</th>\n",
       "      <td>17536335</td>\n",
       "      <td>or dig up</td>\n",
       "      <td>or dig up</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>235</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23511</td>\n",
       "      <td>23510</td>\n",
       "      <td>43420</td>\n",
       "      <td>010915</td>\n",
       "      <td>4.178</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17536335.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288426</th>\n",
       "      <td>17548723</td>\n",
       "      <td>hi Daddy</td>\n",
       "      <td>hi Daddy</td>\n",
       "      <td>hə dæbæbæ</td>\n",
       "      <td>haɪ dædiː</td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23510</td>\n",
       "      <td>23510</td>\n",
       "      <td>43397</td>\n",
       "      <td>010307</td>\n",
       "      <td>1.508</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17548723.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289008</th>\n",
       "      <td>17554468</td>\n",
       "      <td>and there were lots_of babies there too right</td>\n",
       "      <td>and there be lots_of baby there too right</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>question</td>\n",
       "      <td>eng</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>895</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23511</td>\n",
       "      <td>23510</td>\n",
       "      <td>43397</td>\n",
       "      <td>010307</td>\n",
       "      <td>2.908</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17554468.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296020</th>\n",
       "      <td>17561395</td>\n",
       "      <td>cold Arthur pasta</td>\n",
       "      <td>cold Arthur pasta</td>\n",
       "      <td>kod ɔθə pɑstə</td>\n",
       "      <td>koʊld ɑɹθəɹ pɑstə</td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>557</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23510</td>\n",
       "      <td>23510</td>\n",
       "      <td>43431</td>\n",
       "      <td>020012</td>\n",
       "      <td>4.710</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17561395.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297976</th>\n",
       "      <td>17561207</td>\n",
       "      <td>you're trying to be</td>\n",
       "      <td>you try to be</td>\n",
       "      <td>jə twaɪŋ tə biə</td>\n",
       "      <td>jɔɹ tɹaɪɪŋ tuː biː</td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>506</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23510</td>\n",
       "      <td>23510</td>\n",
       "      <td>43441</td>\n",
       "      <td>020306</td>\n",
       "      <td>2.265</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17561207.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311922</th>\n",
       "      <td>17581532</td>\n",
       "      <td>it might be a little early but</td>\n",
       "      <td>it might be a little early but</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>trail off</td>\n",
       "      <td>eng</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1078</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23511</td>\n",
       "      <td>23510</td>\n",
       "      <td>43450</td>\n",
       "      <td>020515</td>\n",
       "      <td>1.361</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17581532.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333358</th>\n",
       "      <td>17597764</td>\n",
       "      <td>it's turning blue</td>\n",
       "      <td>it turn blue</td>\n",
       "      <td>ɪs tʊɜ˞nɪŋ blu</td>\n",
       "      <td>ɪts tʌɹnɪŋ bluː</td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>476</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23510</td>\n",
       "      <td>23510</td>\n",
       "      <td>43467</td>\n",
       "      <td>021008b</td>\n",
       "      <td>1.777</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17597764.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335434</th>\n",
       "      <td>17594756</td>\n",
       "      <td>what's this</td>\n",
       "      <td>what this</td>\n",
       "      <td>ɡwʊθ dɪːθ</td>\n",
       "      <td>wʌts ðɪs</td>\n",
       "      <td>question</td>\n",
       "      <td>eng</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23510</td>\n",
       "      <td>23510</td>\n",
       "      <td>43465</td>\n",
       "      <td>021001</td>\n",
       "      <td>6.125</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17594756.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341692</th>\n",
       "      <td>17616589</td>\n",
       "      <td>are you finished eating</td>\n",
       "      <td>be you finish eat</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>question</td>\n",
       "      <td>eng</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1065</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23511</td>\n",
       "      <td>23510</td>\n",
       "      <td>43472</td>\n",
       "      <td>030000</td>\n",
       "      <td>1.547</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17616589.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342514</th>\n",
       "      <td>17604872</td>\n",
       "      <td>I miss</td>\n",
       "      <td>I miss</td>\n",
       "      <td>aɪ mɪs</td>\n",
       "      <td>aɪ mɪs</td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>336</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23510</td>\n",
       "      <td>23510</td>\n",
       "      <td>43474</td>\n",
       "      <td>030219</td>\n",
       "      <td>2.083</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17604872.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364923</th>\n",
       "      <td>17628362</td>\n",
       "      <td>more water</td>\n",
       "      <td>more water</td>\n",
       "      <td>mo wʌtə</td>\n",
       "      <td>mɔɹ wɑtəɹ</td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>371</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23522</td>\n",
       "      <td>23522</td>\n",
       "      <td>43490</td>\n",
       "      <td>010805</td>\n",
       "      <td>1.841</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17628362.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416731</th>\n",
       "      <td>17678776</td>\n",
       "      <td>h h</td>\n",
       "      <td>h h</td>\n",
       "      <td>eɪtʃ eɪkʰ</td>\n",
       "      <td>eɪʧ eɪʧ</td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>497</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23530</td>\n",
       "      <td>23530</td>\n",
       "      <td>43537</td>\n",
       "      <td>010814</td>\n",
       "      <td>1.609</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17678776.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430387</th>\n",
       "      <td>17693010</td>\n",
       "      <td>I understand that but ya know what that means ...</td>\n",
       "      <td>I understand that but you know what that mean ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>325</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23532</td>\n",
       "      <td>23530</td>\n",
       "      <td>43552</td>\n",
       "      <td>020403</td>\n",
       "      <td>4.401</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17693010.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439456</th>\n",
       "      <td>17697968</td>\n",
       "      <td>oh dear William that's terrible</td>\n",
       "      <td>oh dear William that terrible</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23532</td>\n",
       "      <td>23530</td>\n",
       "      <td>43551</td>\n",
       "      <td>020319</td>\n",
       "      <td>2.807</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17697968.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457869</th>\n",
       "      <td>17739999</td>\n",
       "      <td>try Mom</td>\n",
       "      <td>try Mom</td>\n",
       "      <td>traɪ mɑm</td>\n",
       "      <td>tɹaɪ mɑm</td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1262</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>23530</td>\n",
       "      <td>23530</td>\n",
       "      <td>43569</td>\n",
       "      <td>030125</td>\n",
       "      <td>1.597</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>extracted_wavs/17739999.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              gloss  \\\n",
       "18000   17278081                                          ding dong   \n",
       "44751   17323545               would you like to hear promised land   \n",
       "151803  17425579                                        boots boots   \n",
       "160848  17441440  I don't think you've ever had eggplant but Mom...   \n",
       "179481  17437309                                    come here angel   \n",
       "197711  17457797                                             was it   \n",
       "200312  17458412                                          we did it   \n",
       "206192  17479586                                            red red   \n",
       "206957  17466565                                    um the pink one   \n",
       "207669  17476426                                        there it is   \n",
       "215409  17475018            and the goblins ran back to their homes   \n",
       "217071  17480806                             that is a lot of rings   \n",
       "226738  17501401                                  is that you or me   \n",
       "237362  17492751  yeah would you like me to get you a bowl of so...   \n",
       "252153  17513189                                          eggs eggs   \n",
       "254880  17516827                                        read please   \n",
       "258662  17518193                                 where's the parrot   \n",
       "260876  17534534                I'll eat it you wanna give it to me   \n",
       "266449  17533444                               I see a kid on a mat   \n",
       "277281  17536335                                          or dig up   \n",
       "288426  17548723                                           hi Daddy   \n",
       "289008  17554468      and there were lots_of babies there too right   \n",
       "296020  17561395                                  cold Arthur pasta   \n",
       "297976  17561207                                you're trying to be   \n",
       "311922  17581532                     it might be a little early but   \n",
       "333358  17597764                                  it's turning blue   \n",
       "335434  17594756                                        what's this   \n",
       "341692  17616589                            are you finished eating   \n",
       "342514  17604872                                             I miss   \n",
       "364923  17628362                                         more water   \n",
       "416731  17678776                                                h h   \n",
       "430387  17693010  I understand that but ya know what that means ...   \n",
       "439456  17697968                    oh dear William that's terrible   \n",
       "457869  17739999                                            try Mom   \n",
       "\n",
       "                                                     stem  \\\n",
       "18000                                           ding dong   \n",
       "44751                  will you like to hear promise land   \n",
       "151803                                          boot boot   \n",
       "160848            I do think you ever have but Mommy love   \n",
       "179481                                    come here angel   \n",
       "197711                                              be it   \n",
       "200312                                           we do it   \n",
       "206192                                            red red   \n",
       "206957                                       the pink one   \n",
       "207669                                        there it be   \n",
       "215409              and the goblin run back to their home   \n",
       "217071                              that be a lot of ring   \n",
       "226738                                  be that you or me   \n",
       "237362  yeah will you like me to get you a bowl of som...   \n",
       "252153                                            egg egg   \n",
       "254880                                        read please   \n",
       "258662                                   where the parrot   \n",
       "260876                    I eat it you want give it to me   \n",
       "266449                               I see a kid on a mat   \n",
       "277281                                          or dig up   \n",
       "288426                                           hi Daddy   \n",
       "289008          and there be lots_of baby there too right   \n",
       "296020                                  cold Arthur pasta   \n",
       "297976                                      you try to be   \n",
       "311922                     it might be a little early but   \n",
       "333358                                       it turn blue   \n",
       "335434                                          what this   \n",
       "341692                                  be you finish eat   \n",
       "342514                                             I miss   \n",
       "364923                                         more water   \n",
       "416731                                                h h   \n",
       "430387  I understand that but you know what that mean ...   \n",
       "439456                      oh dear William that terrible   \n",
       "457869                                            try Mom   \n",
       "\n",
       "                          actual_phonology  \\\n",
       "18000                                        \n",
       "44751                                        \n",
       "151803                               bu bu   \n",
       "160848                                       \n",
       "179481                                       \n",
       "197711                              wʌz ɪt   \n",
       "200312                                       \n",
       "206192                            rɛː rɛːd   \n",
       "206957                       ʌm də pɪŋk wə   \n",
       "207669                                       \n",
       "215409  n̩ ə ɡɑblɪŋz wæ̃n bæk tu ðeɪə homz   \n",
       "217071                 ðæd ɪz ə lɑd ə bɪŋz   \n",
       "226738                                       \n",
       "237362                                       \n",
       "252153                         iɡz (.) ɛɡz   \n",
       "254880                            riʔ plis   \n",
       "258662                                       \n",
       "260876                                       \n",
       "266449                                       \n",
       "277281                                       \n",
       "288426                           hə dæbæbæ   \n",
       "289008                                       \n",
       "296020                       kod ɔθə pɑstə   \n",
       "297976                     jə twaɪŋ tə biə   \n",
       "311922                                       \n",
       "333358                      ɪs tʊɜ˞nɪŋ blu   \n",
       "335434                           ɡwʊθ dɪːθ   \n",
       "341692                                       \n",
       "342514                              aɪ mɪs   \n",
       "364923                             mo wʌtə   \n",
       "416731                           eɪtʃ eɪkʰ   \n",
       "430387                                       \n",
       "439456                                       \n",
       "457869                            traɪ mɑm   \n",
       "\n",
       "                             model_phonology                 type language  \\\n",
       "18000                                                 declarative      eng   \n",
       "44751                                                    question      eng   \n",
       "151803                           buːts buːts          declarative      eng   \n",
       "160848                                                declarative      eng   \n",
       "179481                                                declarative      eng   \n",
       "197711                                wɑz ɪt             question      eng   \n",
       "200312                                        imperative_emphatic      eng   \n",
       "206192                               ɹɛd ɹɛd          declarative      eng   \n",
       "206957                        ʌm ðə pɪŋk wʌn          declarative      eng   \n",
       "207669                                                declarative      eng   \n",
       "215409  ænd ðə ɡɑblɪnz ɹæn bæk tuː ðɛɹ hoʊmz          declarative      eng   \n",
       "217071                  ðæt ɪz ə lɑt ʌv ɹɪŋz          declarative      eng   \n",
       "226738                                                   question      eng   \n",
       "237362                                                   question      eng   \n",
       "252153                           ɛɡz (.) ɛɡz          declarative      eng   \n",
       "254880                            ɹiːd pliːz          declarative      eng   \n",
       "258662                                                   question      eng   \n",
       "260876                                                   question      eng   \n",
       "266449                                                declarative      eng   \n",
       "277281                                                declarative      eng   \n",
       "288426                             haɪ dædiː          declarative      eng   \n",
       "289008                                                   question      eng   \n",
       "296020                     koʊld ɑɹθəɹ pɑstə          declarative      eng   \n",
       "297976                    jɔɹ tɹaɪɪŋ tuː biː          declarative      eng   \n",
       "311922                                                  trail off      eng   \n",
       "333358                       ɪts tʌɹnɪŋ bluː          declarative      eng   \n",
       "335434                              wʌts ðɪs             question      eng   \n",
       "341692                                                   question      eng   \n",
       "342514                                aɪ mɪs          declarative      eng   \n",
       "364923                             mɔɹ wɑtəɹ          declarative      eng   \n",
       "416731                               eɪʧ eɪʧ          declarative      eng   \n",
       "430387                                                declarative      eng   \n",
       "439456                                                declarative      eng   \n",
       "457869                              tɹaɪ mɑm          declarative      eng   \n",
       "\n",
       "        num_morphemes  num_tokens  utterance_order  ... corpus_id speaker_id  \\\n",
       "18000               2           2              416  ...       336      23473   \n",
       "44751               9           7             1653  ...       336      23473   \n",
       "151803              4           2             1629  ...       336      23495   \n",
       "160848             13          11             1746  ...       336      23497   \n",
       "179481              3           3              315  ...       336      23497   \n",
       "197711              4           2              180  ...       336      23495   \n",
       "200312              4           3              207  ...       336      23497   \n",
       "206192              2           2             1408  ...       336      23495   \n",
       "206957              3           4              192  ...       336      23495   \n",
       "207669              4           3              904  ...       336      23497   \n",
       "215409             11           8              304  ...       336      23495   \n",
       "217071              8           6              576  ...       336      23495   \n",
       "226738              6           5             1330  ...       336      23497   \n",
       "237362             19          18                1  ...       336      23497   \n",
       "252153              4           2              298  ...       336      23510   \n",
       "254880              3           2              381  ...       336      23495   \n",
       "258662              4           3              256  ...       336      23511   \n",
       "260876             11           9             1300  ...       336      23511   \n",
       "266449              7           7              999  ...       336      23511   \n",
       "277281              3           3              235  ...       336      23511   \n",
       "288426              2           2              313  ...       336      23510   \n",
       "289008             10           8              895  ...       336      23511   \n",
       "296020              3           3              557  ...       336      23510   \n",
       "297976              6           4              506  ...       336      23510   \n",
       "311922              7           7             1078  ...       336      23511   \n",
       "333358              5           3              476  ...       336      23510   \n",
       "335434              3           2              201  ...       336      23510   \n",
       "341692              7           4             1065  ...       336      23511   \n",
       "342514              2           2              336  ...       336      23510   \n",
       "364923              2           2              371  ...       336      23522   \n",
       "416731              2           2              497  ...       336      23530   \n",
       "430387             16          14              325  ...       336      23532   \n",
       "439456              6           5              107  ...       336      23532   \n",
       "457869              2           2             1262  ...       336      23530   \n",
       "\n",
       "       target_child_id transcript_id filename_identifier media_duration  \\\n",
       "18000            23471         43232              020411          1.998   \n",
       "44751            23471         43247              021108          6.259   \n",
       "151803           23495         43324              010719          3.345   \n",
       "160848           23495         43335              020011          3.487   \n",
       "179481           23495         43344              020227          0.777   \n",
       "197711           23495         43364              020813          1.198   \n",
       "200312           23495         43361              020721          2.940   \n",
       "206192           23495         43366              020904          9.045   \n",
       "206957           23495         43367              020909          5.157   \n",
       "207669           23495         43367              020909          2.040   \n",
       "215409           23495         43365              020819          4.216   \n",
       "217071           23495         43369              020923          2.095   \n",
       "226738           23495         43381              030323          0.993   \n",
       "237362           23495         43363              020806          3.340   \n",
       "252153           23510         43401              010410          3.173   \n",
       "254880           23495         43389              040002          1.256   \n",
       "258662           23510         43404              010502          2.669   \n",
       "260876           23510         43407              010604          2.090   \n",
       "266449           23510         43412              010710          5.680   \n",
       "277281           23510         43420              010915          4.178   \n",
       "288426           23510         43397              010307          1.508   \n",
       "289008           23510         43397              010307          2.908   \n",
       "296020           23510         43431              020012          4.710   \n",
       "297976           23510         43441              020306          2.265   \n",
       "311922           23510         43450              020515          1.361   \n",
       "333358           23510         43467             021008b          1.777   \n",
       "335434           23510         43465              021001          6.125   \n",
       "341692           23510         43472              030000          1.547   \n",
       "342514           23510         43474              030219          2.083   \n",
       "364923           23522         43490              010805          1.841   \n",
       "416731           23530         43537              010814          1.609   \n",
       "430387           23530         43552              020403          4.401   \n",
       "439456           23530         43551              020319          2.807   \n",
       "457869           23530         43569              030125          1.597   \n",
       "\n",
       "        num_words contains_xxx  contains_yyy                   output_wav  \n",
       "18000           2        False         False  extracted_wavs/17278081.wav  \n",
       "44751           7        False         False  extracted_wavs/17323545.wav  \n",
       "151803          2        False         False  extracted_wavs/17425579.wav  \n",
       "160848         11        False         False  extracted_wavs/17441440.wav  \n",
       "179481          3        False         False  extracted_wavs/17437309.wav  \n",
       "197711          2        False         False  extracted_wavs/17457797.wav  \n",
       "200312          3        False         False  extracted_wavs/17458412.wav  \n",
       "206192          2        False         False  extracted_wavs/17479586.wav  \n",
       "206957          4        False         False  extracted_wavs/17466565.wav  \n",
       "207669          3        False         False  extracted_wavs/17476426.wav  \n",
       "215409          8        False         False  extracted_wavs/17475018.wav  \n",
       "217071          6        False         False  extracted_wavs/17480806.wav  \n",
       "226738          5        False         False  extracted_wavs/17501401.wav  \n",
       "237362         18        False         False  extracted_wavs/17492751.wav  \n",
       "252153          2        False         False  extracted_wavs/17513189.wav  \n",
       "254880          2        False         False  extracted_wavs/17516827.wav  \n",
       "258662          3        False         False  extracted_wavs/17518193.wav  \n",
       "260876          9        False         False  extracted_wavs/17534534.wav  \n",
       "266449          7        False         False  extracted_wavs/17533444.wav  \n",
       "277281          3        False         False  extracted_wavs/17536335.wav  \n",
       "288426          2        False         False  extracted_wavs/17548723.wav  \n",
       "289008          8        False         False  extracted_wavs/17554468.wav  \n",
       "296020          3        False         False  extracted_wavs/17561395.wav  \n",
       "297976          4        False         False  extracted_wavs/17561207.wav  \n",
       "311922          7        False         False  extracted_wavs/17581532.wav  \n",
       "333358          3        False         False  extracted_wavs/17597764.wav  \n",
       "335434          2        False         False  extracted_wavs/17594756.wav  \n",
       "341692          4        False         False  extracted_wavs/17616589.wav  \n",
       "342514          2        False         False  extracted_wavs/17604872.wav  \n",
       "364923          2        False         False  extracted_wavs/17628362.wav  \n",
       "416731          2        False         False  extracted_wavs/17678776.wav  \n",
       "430387         14        False         False  extracted_wavs/17693010.wav  \n",
       "439456          5        False         False  extracted_wavs/17697968.wav  \n",
       "457869          2        False         False  extracted_wavs/17739999.wav  \n",
       "\n",
       "[34 rows x 33 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_utts_to_score = utts_to_score.loc[utts_to_score.output_wav != 'Error extracting WAV']\n",
    "final_utts_to_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b01379c-81b8-4e83-9688-546e161c9439",
   "metadata": {},
   "source": [
    "# Recognize All and Compute WER By Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc68bc8d-fc51-4b47-9aa9-35011f1c5d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 14:49:15 optimizers:54] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-03-29 14:49:16 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import os, shutil, wget\n",
    "import ctc_decoders\n",
    "import copy\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import cdl_asr\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "669c4677-490d-4608-9f7e-052390c42a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cdl_asr' from '/home/stephan/notebooks/cdl-asr/cdl_asr.py'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(cdl_asr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee2949-bb93-49f9-9165-d262a4bac3c6",
   "metadata": {},
   "source": [
    "### With Neural Rescoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1890f00-f088-4973-b304-d960979fabe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-03-29 17:01:32 cloud:56] Found existing object /home/stephan/.cache/torch/NeMo/NeMo_1.16.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo.\n",
      "[NeMo I 2023-03-29 17:01:32 cloud:62] Re-using file from: /home/stephan/.cache/torch/NeMo/NeMo_1.16.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo\n",
      "[NeMo I 2023-03-29 17:01:32 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2023-03-29 17:01:32 features:286] PADDING: 16\n",
      "[NeMo I 2023-03-29 17:01:33 audio_preprocessing:513] Numba CUDA SpecAugment kernel is being used\n",
      "[NeMo I 2023-03-29 17:01:33 save_restore_connector:247] Model EncDecCTCModel was successfully restored from /home/stephan/.cache/torch/NeMo/NeMo_1.16.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo.\n"
     ]
    }
   ],
   "source": [
    "# load all models\n",
    "#lm_path = '/home/stephan/notebooks/child-directed-listening/output/ngram/childes_chi_sep_punct.LM'\n",
    "lm_path = 'lowercase_3-gram.pruned.1e-7.arpa'\n",
    "asr_model = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name='QuartzNet15x5Base-En', strict=False)\n",
    "# use BERT to rescore the hypotheses\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('/home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/train/n=5000/Providence_all_no_tagsxBERT')\n",
    "bertMaskedLM = BertForMaskedLM.from_pretrained('/home/stephan/notebooks/child-directed-listening/output/experiments/full_scale/train/n=5000/Providence_all_no_tagsxBERT')\n",
    "bertMaskedLM.eval()\n",
    "bertMaskedLM.to('cuda')  # if you have gpu\n",
    "vocab =  np.array(bert_tokenizer.convert_ids_to_tokens(range(bert_tokenizer.vocab_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73d4a635-7485-4a77-bcd1-fba2a38ae005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_transcription(filepath, rescore):\n",
    "    candidates = cdl_asr.transcribe_with_neural_rescoring([filepath],\n",
    "        lm_path,\n",
    "        asr_model,\n",
    "        bertMaskedLM,\n",
    "        vocab,\n",
    "        bert_tokenizer,\n",
    "        num_hypotheses=64,\n",
    "        alpha=.8,\n",
    "        rescore = rescore)    \n",
    "    return candidates.iloc[0].hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3363d2ac-1477-4bbf-89ea-431b48069934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319f188666f94d49900a0884c3b27171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"tink o down\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd2a5aa549648cb9b5af4edddaec8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: did\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:01:45 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:01:45 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673d8ceb7c2e49828795217060fdb9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"would you like to hear promised land\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ce8d10544e480788f217b8d4ec4916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: would you like to hear promised\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:02:00 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:02:00 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7247ae1d6f4cae984ab7eb06bb2641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"i will become i lician an trouliing\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252514823955410592db701006d0cf4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: illegitimate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:02:12 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:02:12 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22682c3b3104431ba53ab56edd1c18b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"i don't think you've ever had an plan but mommy loves egg plant\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1854517aafc144938391946775822f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: i don't think you overhauled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:02:28 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:02:28 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7255b73476b4547b3fc451b5cc183c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"laran john\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c81175106cc447bacd4f478009309d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: marion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:02:38 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:02:38 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c5337b1e3f44adae71b02d2a21705f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"who is it\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12530987f849495684b0f124e0445bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: his\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:02:49 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:02:49 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a189ea0d541413ba529117ab499ad59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"we did it\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ce0eee9e324d7ab5c9b8717587d84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: edith\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:03:00 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:03:00 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac6bed05ac84fa497f8d2bd92e0f845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"en all seven coblors had arengle\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63551171c69c444385c760f609d69e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: allen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:03:12 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:03:12 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea2540c557646f2b9ea307233f82607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"um the pin cod\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470047eb62a84417b9f43e4d81391b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: the pain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:03:25 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:03:25 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8b676277c844be9646a9b5ea67a74f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"where it is\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf990a1b6db43f1bce7af8a009d9ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: there is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:03:36 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:03:36 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4396e6e0e35479dae37c16926b7dc87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"calan ran back to the hoom\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1309bdf319f844789388e9444175479a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: colonisation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:03:48 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:03:48 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209d0f59639e4a2f80e9a5726d6204b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"ineen no large of things\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa4a96231594ecdab1406e4695fd5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: enlarging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:04:00 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:04:00 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63183affad1430284567922e5f1dd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"that you or me\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8828ec6b6e2f496e887f4203a4e51921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:04:11 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:04:11 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386c6167e7a4458c907f283ffae0a81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"would you like me to get you a bowl of something and you can pretend a cook\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030f076562b44d959936300b429d10fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: dyumatsena ballinamoyle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:04:28 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:04:28 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3055c927a25e4c67ad29cd282340f6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"ey would you like some egg\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46715cb140946519601923c13beccdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: would you like some\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:04:41 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:04:41 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587d1912480d47cc8710c51d7c7b930e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \" please\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74f001f48f547cf917ff534b9684d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: please\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:04:54 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:04:54 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1691f5d1a82a4c78a7b38b5bd28c53d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"wheres the parents\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50eedca4dbb8408ba49594482ef6cd90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: there the parents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:05:10 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:05:10 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e5c108012c40e9b89c0be363a990ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"i'll ead it you don't give it to me\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8e4308bd934ea78a9458dd74e0d022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: illegitimate \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:05:24 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:05:24 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84781e61ccb24020bf1b55703a2fb45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"and that kid i set kid on a mat\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c882706e9164ab680db942063501ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: antagonistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:05:37 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:05:37 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ca1b1b9f55457086314798b6aa24de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"or dig up\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2a188623e74576b427ff0480ad48c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: orde\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:05:50 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:05:50 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48569f2d21fc45d08854a13257277196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"o o mo o\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5a65f458b84652963f1242380ad1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: one\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:06:04 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:06:04 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f21cf1359542f8a6ca56945b4b2c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"an there were lots of babies there too right\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca0daf058c743d0bb0a17bad3de06c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: there were lots of banishment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:06:23 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:06:23 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47c65e2390542f8ac7a8adad6f6d03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"good ala te pansyes there is colled arthur poste do you want som\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5cca2573f94cc1a51b55c7aa95b435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: goodhearted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:06:38 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:06:38 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786b5d15f59a4d55ba16a9ccc58b35f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \" \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023078e0b4384bc29a233b89a2672fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:06:50 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:06:50 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca74655ac4034d18a9c3c406bbc06489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"oh\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e20383f1b464c04bacf6f4f4263adf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:07:02 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:07:02 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3735730583644039020c5592e9a6bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"tuning bluw\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b6d6bde34c484db25bf697adfe5345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: turning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:07:17 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:07:17 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3a1d6f2a614d4a85e92ec6d582c6d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"oky let's try and put this on turbco and might help it i it's just cold it's a cold beck\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a59a3f74d74548a4158ea52d73469e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: lettice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:07:32 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:07:32 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa71cf29d9434aecac80e617208e2b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"are you finished\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e389ada931442eb523755341509353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: aroused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:07:48 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:07:48 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1257aee1ded542d3a0bb8b42be4abaed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"i now\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd16d5ce1cdc4f8b9fa56c04fc74bad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:08:00 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:08:00 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bafc677a9e54297ae9c6f057e697c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"no wha actom\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd1eca15d4f4c11abe833c4f7db09b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:08:13 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:08:13 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37afdebb6564aa0b5ac07200a6f11f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"e  e\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da60d6b7dfd46e2b0b9c134174114d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:08:28 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:08:28 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022d593c97274315af21c94428e47cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"i understand that but you know what that means you have to wear the microphone\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61667d2e082f409f8b0c69199af781b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: i understand that you know what that means to have weathercock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:08:54 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:08:54 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38bd8b4d51a64c208f7ff38e781323af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"oh dear william that's terrible\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a313adb840543e39ae2ce79d7942a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: dear william that's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:09:11 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:09:11 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50c9b8a092f4e949b79fa54ebdba710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"han mon\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fb20422adc4cec960b37ac5f8b3e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: hang\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:09:23 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:135: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      all_hypotheses['bert_prob'] = [compute_prob_for_all_masks(hypothesis, bertMaskedLM, vocab, tokenizer, return_type='prob') for hypothesis in all_hypotheses.hypothesis]\n",
      "    \n",
      "[NeMo W 2023-03-29 17:09:23 nemo_logging:349] /home/stephan/notebooks/cdl-asr/cdl_asr.py:148: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      return(rescored_hypotheses)\n",
      "    \n",
      "[NeMo W 2023-03-29 17:09:23 nemo_logging:349] <timed exec>:1: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 16s, sys: 47.5 s, total: 8min 3s\n",
      "Wall time: 7min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_utts_to_score['neural_transcription'] = [get_top_transcription(x, True) for x in final_utts_to_score.output_wav]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd68409e-e8b8-4dcb-8c45-575c79fdc011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:09:23 nemo_logging:349] /tmp/ipykernel_2743583/2749184977.py:1: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      final_utts_to_score['neural_WER'] = [torchmetrics.functional.word_error_rate(x['neural_transcription'],\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "final_utts_to_score['neural_WER'] = [torchmetrics.functional.word_error_rate(x['neural_transcription'], \n",
    "    x['gloss']).item() for x in final_utts_to_score.to_dict('records')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9fa1d45-033d-4278-907e-db7cae0abe8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18000     1.000000\n",
       "44751     0.285714\n",
       "151803    1.000000\n",
       "160848    0.818182\n",
       "179481    1.000000\n",
       "197711    1.000000\n",
       "200312    1.000000\n",
       "206192    1.000000\n",
       "206957    0.500000\n",
       "207669    0.000000\n",
       "215409    1.000000\n",
       "217071    1.000000\n",
       "226738    1.000000\n",
       "237362    1.000000\n",
       "252153    2.000000\n",
       "254880    0.500000\n",
       "258662    0.666667\n",
       "260876    1.000000\n",
       "266449    1.000000\n",
       "277281    1.000000\n",
       "288426    1.000000\n",
       "289008    0.875000\n",
       "296020    1.000000\n",
       "297976    1.000000\n",
       "311922    1.000000\n",
       "333358    0.666667\n",
       "335434    1.000000\n",
       "341692    1.000000\n",
       "342514    1.000000\n",
       "364923    1.000000\n",
       "416731    1.000000\n",
       "430387    0.571429\n",
       "439456    0.800000\n",
       "457869    1.000000\n",
       "Name: neural_WER, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_utts_to_score['neural_WER']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fed5e4-42d5-410c-b9c1-662d7ef1c814",
   "metadata": {},
   "source": [
    "### Without Neural Rescoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f80ce7b-df98-4d66-902a-754ea338528b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b7a7c548524dc081de1f48da48202f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"tink o down\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970f2554537d4bb78b292fbe509ea7eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: did\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9adb98693d074d0e846af7526cf06015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"would you like to hear promised land\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528d3309dbb44bf5b0b3a163d7c9f070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: would you like to hear promised\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b66828774f047afb9fec3f60c88ce4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"i will become i lician an trouliing\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5bae91304834da3a5120d5aaa4555f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: illegitimate\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ffb41ca34b47f98c77a937a07770df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"i don't think you've ever had an plan but mommy loves egg plant\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b869a2ef7ee44235a980756d1825b98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: i don't think you overhauled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cfcbc3489ac4be79586fc869183b223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"laran john\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83969da05a2049bfa84ce0528be6853b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: marion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b218393a4034477819df3b08def379a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"who is it\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a99cef0e51b478f970be81729147b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: his\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b117535c8a9482fbb64834368af2c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"we did it\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679dea100f85455b9571d229e9c0314e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: edith\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb781d9233744129ff67c37c0fb8314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"en all seven coblors had arengle\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9931b6553b948beaa9bf86a0f48c9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: allen\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3339a158af42e4a1da1fc45c2b40cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"um the pin cod\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a6e10c77d0471cb3f0c2861a086ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: the pain\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbfe6681f4d40ccb19f75a3e68b9380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"where it is\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59019e91e0384a728025f871c5e3eee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: there is\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9deaed9cc9fb43fb9e99726a90f00e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"calan ran back to the hoom\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf207aeb416b470c8bd4418d26fd5606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: colonisation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b151135ba34340cd91ccd563c425f3cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"ineen no large of things\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a91989a1cb14f6eb70fa5003e0405eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: enlarging\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103be763d3ab4c369ea179c4d5a6a485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"that you or me\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50e96052b2c4a9a9551130163076e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: you\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad99a9525c84445b38e98f980018755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"would you like me to get you a bowl of something and you can pretend a cook\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642c4b364c5f48d2b5d024ecb0a61d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: dyumatsena ballinamoyle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c17946105045b9b9d0c28ab1b9714d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"ey would you like some egg\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89fbe5feeb474541bc435d4c34aebe40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: would you like some\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375e902872484ec0a68c2ab2e96b0323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \" please\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba78eef0fd584ef0b4a1ee64f8288c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: please\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28529f4393084599b9e659276b2c2415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"wheres the parents\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7d205089d44340b0f882a70c87f17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: there the parents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b01a9cd5d4a4c148c1e06610f24e03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"i'll ead it you don't give it to me\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc282a1bcb78466cad4cab420361ab15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: illegitimate \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c881f5335e4903b0e934b654e9ee43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"and that kid i set kid on a mat\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83bee1e18f694de4a3b5da1c674d22f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: antagonistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9746a92fb3945cdbd07763ff12e919f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"or dig up\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcec124fa2c94f8893f0da0ee69268a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: orde\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7745b0a99447df998bc4bdca439422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"o o mo o\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381a69b762234f41956ba29837c8dd28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: one\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8270184d6654b7d846f0151bfa8aef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"an there were lots of babies there too right\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c452a82d944ed6a1a890bae3af7381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: there were lots of banishment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5873c356cbc5499383d3ee9b0ea20850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"good ala te pansyes there is colled arthur poste do you want som\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aaf5695ddd54846b471427af5fad14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: goodhearted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c2f1bd08814888a631298e33c214bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \" \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47a2255d2a84ea682f9b5affa88ee8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79040d15f9ec46ec8a8793976839f3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"oh\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1a7b9b653a4ef48de155120c3e8a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d704eeff9b14328a3b7520358f35ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"tuning bluw\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c9fa464caf4c95b2ba3ceef7d766ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: turning\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0592daedbad4100b043bea7d039c865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"oky let's try and put this on turbco and might help it i it's just cold it's a cold beck\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecf0e4bb12f49cda21aa2e67eb70ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: lettice\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b892925fc12748a8865803719e682044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"are you finished\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4af7984c38347868bd0b499b16592e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: aroused\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2066c882dee487895f3629d8d0ae32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"i now\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c343fa893fbb41769be5682a36db4dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9e3973f6a840a8b6e4ad52d64b6ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"no wha actom\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048cd5380b604e9b932bdbef5937c152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: now\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b543f3d460e84d66b20348041ae52e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"e  e\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8acf51f0ba4ecb8cf79be50a330103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: i\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e420d8decec4268b48f30951ac9b916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"i understand that but you know what that means you have to wear the microphone\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574289bc53e7497aab8c79c023c069fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: i understand that you know what that means to have weathercock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187f0e7560dd4bb0928187365dc47784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"oh dear william that's terrible\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8f22d8317b4529951f6ed6aa026f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: dear william that's\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70bb2f5442df45209b87868a2ba1b54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"han mon\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4211496af142d380a73891766faec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "[NeMo W 2023-03-29 17:16:16 nemo_logging:349] /tmp/ipykernel_2743583/1811969063.py:1: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      final_utts_to_score['trigram_transcription'] = [get_top_transcription(x, False) for x in final_utts_to_score.output_wav]\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis after ngram: hang\n"
     ]
    }
   ],
   "source": [
    "final_utts_to_score['trigram_transcription'] = [get_top_transcription(x, False) for x in final_utts_to_score.output_wav]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e9b9972-df4c-46e0-92fe-d56877c7075b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-29 17:16:17 nemo_logging:349] /tmp/ipykernel_2743583/3962398152.py:1: SettingWithCopyWarning: \n",
      "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "    Try using .loc[row_indexer,col_indexer] = value instead\n",
      "    \n",
      "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "      final_utts_to_score['trigram_WER'] = [torchmetrics.functional.word_error_rate(x['trigram_transcription'],\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "final_utts_to_score['trigram_WER'] = [torchmetrics.functional.word_error_rate(x['trigram_transcription'], \n",
    "    x['gloss']).item() for x in final_utts_to_score.to_dict('records')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3fe838af-87b6-4e32-82d0-93cc4374d5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaker_code\n",
       "CHI    0.980392\n",
       "MOT    0.824529\n",
       "Name: neural_WER, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_utts_to_score.groupby('speaker_code')['neural_WER'].agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ecfed736-3cf6-48bc-b510-55e4705981f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaker_code\n",
       "CHI    0.995098\n",
       "MOT    0.804851\n",
       "Name: trigram_WER, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_utts_to_score.groupby('speaker_code')['trigram_WER'].agg(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369f00ae-df12-4dba-8a16-18498e51513b",
   "metadata": {},
   "source": [
    "# Todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f6eb884-c745-4c95-918f-a24aca5c4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [X] figure out why there are some with invalid duration specifications\n",
    "# [X] subset the utterances to ones that finished\n",
    "# [wontfix] transcribe_with_neural_rescoring only handles one file at a time\n",
    "# [ ] get missing mp3s eg for Ethan\n",
    "# [ ] Send WAVs through programmatic cleanup / preprocessing\n",
    "# [ ] VAD and only detect things with speech. Strategy for dealing with silence in between speech vs. stripping\n",
    "# [ ] get more details of CTC model from NEMO\n",
    "# [ ] play with the alpha value -- upweight the ngram model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdl-asr-env",
   "language": "python",
   "name": "cdl-asr-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
